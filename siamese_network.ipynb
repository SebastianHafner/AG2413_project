{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from pathlib import Path\n",
    "from shutil import copy\n",
    "from imageio import imread\n",
    "from sklearn.feature_extraction import image\n",
    "import numpy as np\n",
    "\n",
    "images_dir = Path('Onera Satellite Change Detection dataset - Images/')\n",
    "labels_dir = Path('Onera Satellite Change Detection dataset - Train Labels/')\n",
    "\n",
    "# creating parent folder for new data structure\n",
    "preprocessed_dir = Path('preprocessed/')\n",
    "if not preprocessed_dir.exists(): preprocessed_dir.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aguasclaras', 'bercy', 'bordeaux', 'nantes', 'paris', 'rennes', 'saclay_e', 'abudhabi', 'cupertino', 'pisa', 'beihai', 'hongkong', 'beirut', 'mumbai']\n"
     ]
    }
   ],
   "source": [
    "# loading all raw data into new structure\n",
    "def loading_data(dataset):\n",
    "    \n",
    "    pre_images_dir = preprocessed_dir / dataset / 'pre'\n",
    "    if not pre_images_dir.exists(): pre_images_dir.mkdir(parents=True)\n",
    "    \n",
    "    post_images_dir = preprocessed_dir / dataset / 'post'\n",
    "    if not post_images_dir.exists(): post_images_dir.mkdir(parents=True)\n",
    "        \n",
    "    clabels_dir = preprocessed_dir / dataset / 'labels'\n",
    "    if not clabels_dir.exists(): clabels_dir.mkdir(parents=True)\n",
    "    \n",
    "    with open(images_dir / f'{dataset}.txt') as f:\n",
    "        cities = f.read().strip('\\n').split(',')\n",
    "    print(cities)\n",
    "    \n",
    "    def move_png_to_preprocessed(city):\n",
    "        \n",
    "        # renaming and moving images and labels\n",
    "        image_pair_dir = images_dir / city / 'pair'\n",
    "        \n",
    "        pre_image = image_pair_dir / 'img1.png'\n",
    "        copy(str(pre_image), str(pre_images_dir / f'{city}_pre.png'))\n",
    "        \n",
    "        post_image = image_pair_dir / 'img2.png'\n",
    "        copy(str(post_image), str(post_images_dir / f'{city}_post.png'))\n",
    "        \n",
    "        label = labels_dir / city / 'cm' / 'cm.png'\n",
    "        copy(str(label), str(clabels_dir / f'{city}_label.png'))\n",
    "        \n",
    "    for city in cities:\n",
    "        move_png_to_preprocessed(city)\n",
    "        \n",
    "    return cities\n",
    "    \n",
    "    \n",
    "cities = loading_data('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(233, 15, 15, 7)\n",
      "(131, 15, 15, 7)\n",
      "(224, 15, 15, 7)\n",
      "(288, 15, 15, 7)\n",
      "(148, 15, 15, 7)\n",
      "(178, 15, 15, 7)\n",
      "(421, 15, 15, 7)\n",
      "(605, 15, 15, 7)\n",
      "(774, 15, 15, 7)\n",
      "(536, 15, 15, 7)\n",
      "(673, 15, 15, 7)\n",
      "(358, 15, 15, 7)\n",
      "(1231, 15, 15, 7)\n",
      "(458, 15, 15, 7)\n",
      "6258\n"
     ]
    }
   ],
   "source": [
    "def sample_data(root_dir, cities, fraction=1e-6, patch_size=(15,15)):\n",
    "    \n",
    "    \n",
    "    samples = []\n",
    "    \n",
    "    for city in cities:\n",
    "        \n",
    "        pre_file = root_dir / 'pre' / f'{city}_pre.png'\n",
    "        post_file = root_dir / 'post' / f'{city}_post.png'\n",
    "        label_file = root_dir / 'labels' / f'{city}_label.png'\n",
    "        \n",
    "        pre = imread(pre_file)[:,:,:3] / 255\n",
    "        post = imread(post_file)[:,:,:3] / 255\n",
    "        label = imread(label_file)[:,:,0] / 255\n",
    "        \n",
    "        # print(pre.shape, post.shape, label.shape)\n",
    "        \n",
    "        # stacking\n",
    "        pre1 = pre[:,:,0]\n",
    "        pre2 = pre[:,:,1]\n",
    "        pre3 = pre[:,:,2]\n",
    "        \n",
    "        post1 = post[:,:,0]\n",
    "        post2 = post[:,:,1]\n",
    "        post3 = post[:,:,2]\n",
    "        \n",
    "        layers = [pre1, pre2, pre3, post1, post2, post3, label]\n",
    "        \n",
    "        stack = np.stack(layers, axis=-1)\n",
    "        # print(stack.shape)\n",
    "        \n",
    "        patches = image.extract_patches_2d(stack, (15, 15), max_patches=0.001)\n",
    "        \n",
    "        # patches = extract_patches_2d(layers, patch_size=(15,15), max_patches=fraction) # maybe work with random state\n",
    "        \n",
    "        print(patches.shape)\n",
    "        n_samples = patches.shape[0]\n",
    "        for i in range(n_samples):\n",
    "            pre_img = patches[i,:,:,:3]\n",
    "            post_img = patches[i,:,:,3:6]\n",
    "            label = patches[i,:,:,6][7,7]\n",
    "        \n",
    "            sample = {\n",
    "                'pre': pre_img,\n",
    "                'post': post_img,\n",
    "                'label': label,\n",
    "                'city': city\n",
    "            }\n",
    "        \n",
    "            samples.append(sample)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    return samples\n",
    "\n",
    "root_dir = Path('preprocessed/train/')\n",
    "samples = sample_data(root_dir, cities, fraction=1e-6, patch_size=(15,15))\n",
    "print(len(samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_siamese_model(input_shape):\n",
    "    \"\"\"\n",
    "        Model architecture\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the tensors for the two input images\n",
    "    left_input = Input(input_shape)\n",
    "    right_input = Input(input_shape)\n",
    "    \n",
    "    # Convolutional Neural Network\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (10,10), activation='relu', input_shape=input_shape,\n",
    "                   kernel_initializer=initialize_weights, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (7,7), activation='relu',\n",
    "                     kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (4,4), activation='relu', kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(256, (4,4), activation='relu', kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='sigmoid',\n",
    "                   kernel_regularizer=l2(1e-3),\n",
    "                   kernel_initializer=initialize_weights,bias_initializer=initialize_bias))\n",
    "    \n",
    "    # Generate the encodings (feature vectors) for the two images\n",
    "    encoded_l = model(left_input)\n",
    "    encoded_r = model(right_input)\n",
    "    \n",
    "    # Add a customized layer to compute the absolute difference between the encodings\n",
    "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "    \n",
    "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "    prediction = Dense(1,activation='sigmoid',bias_initializer=initialize_bias)(L1_distance)\n",
    "    \n",
    "    # Connect the inputs with the outputs\n",
    "    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "    \n",
    "    # return the model\n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGeneratorSiamese(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, samples, batch_size=32, input_size=(15,15,3), shuffle=True):\n",
    "        'Initialization'\n",
    "        self.samples = samples\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.patch_size = (input_size[0], input_size[1])\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.samples))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.samples) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(indexes)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "\n",
    "    def __data_generation(self, indexes):\n",
    "        'Generates data containing batch_size samples' \n",
    "        # Initialization\n",
    "        # X : (n_samples, *input_size)\n",
    "        X = np.empty((self.batch_size, *self.input_size))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        \n",
    "        # Generate data\n",
    "        for i, index in enumerate(indexes):\n",
    "            image_patch, label = patch_sample(self.image_files[index], self.label_files[index], self.patch_size)\n",
    "            # print(image_patch.shape, X.shape)\n",
    "            X[i,] = image_patch\n",
    "            y[i] = label\n",
    "\n",
    "        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "\n",
    "        \n",
    "\n",
    "def patch_sample(image_file, label_file, patch_size):\n",
    "    # print(image_file.name, label_file.name)\n",
    "    \n",
    "    patch_nr = 1\n",
    "    \n",
    "    img = imageio.imread(image_file)\n",
    "    img = img[:,:,:3] # removing alpha channel\n",
    "    img = img / 255 # rescaling to [0, 1]\n",
    "    \n",
    "    label = imageio.imread(label_file)\n",
    "    label = label[:,:,0] # only using first band\n",
    "    label = label / 255 # rescaling to [0, 1]\n",
    "\n",
    "    \n",
    "    # fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(20,10))\n",
    "    # left, right = axs\n",
    "    # left.imshow(img)\n",
    "    # right.imshow(label)\n",
    "    \n",
    "    \n",
    "    labeled_img = np.stack([img[:,:,0],img[:,:,1],img[:,:,2],label], axis=-1)\n",
    "    labeled_img_patches = extract_patches_2d(labeled_img, patch_size=patch_size, max_patches=patch_nr)\n",
    "    \n",
    "    image_patch = labeled_img_patches[0,:,:,:3]\n",
    "    label_patch = labeled_img_patches[0,:,:,3]\n",
    "    \n",
    "    if patch_size[0] % 2 == 0:\n",
    "        i = patch_size[0] // 2 - 1\n",
    "        label_subpatches = label_patch[i:i+2, i:i+2]\n",
    "        # labels = np.zeros((patch_nr,2),dtype=np.int8)\n",
    "\n",
    "        n_urban = np.sum(label_subpatches[:,:])\n",
    "        label = 1 if n_urban >=2 else 0\n",
    "    else:\n",
    "        i = patch_size // 2\n",
    "        label = label_patch[i,i]\n",
    "        \n",
    "    return image_patch, label\n",
    "\n",
    "\n",
    "def sophisticated_pick(label_patches):\n",
    "    \n",
    "    n_samples, *rest = image_patches\n",
    "    \n",
    "    likelihoods = []\n",
    "    for i in range(n_samples):\n",
    "        patch = image_patches\n",
    "        \n",
    "    \n",
    "    pass\n",
    "\n",
    "def augmentation(image_patch):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (16, 16, 3)\n",
    "N_CLASSES = 2\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "dir_images = Path('data/preprocessed/images/')\n",
    "dir_labels = Path('data/preprocessed/labels/')\n",
    "\n",
    "image_files = [obj for obj in Path(dir_images).glob('**/*') if obj.is_file()]\n",
    "label_files = [obj for obj in Path(dir_labels).glob('**/*') if obj.is_file()]\n",
    "\n",
    "training_generator = DataGenerator(image_files, label_files, batch_size=BATCH_SIZE, input_size=INPUT_SIZE,\n",
    "                                   n_classes=N_CLASSES, shuffle=True)\n",
    "\n",
    "model = get_siamese_network(INPUT_SIZE, N_CLASSES)\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(lr=0.00006), \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Train model on dataset\n",
    "model.fit(x=training_generator, use_multiprocessing=False, workers=1, verbose=1, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (427, 640, 3)\n",
      "Patches shape: (272214, 2, 2, 3)\n",
      "[[[174 201 231]\n",
      "  [174 201 231]]\n",
      "\n",
      " [[173 200 230]\n",
      "  [173 200 230]]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_sample_image\n",
    "from sklearn.feature_extraction import image\n",
    "# Use the array data from the first image in this dataset:\n",
    "one_image = load_sample_image(\"china.jpg\")\n",
    "print('Image shape: {}'.format(one_image.shape))\n",
    "patches = image.extract_patches_2d(one_image, (2, 2))\n",
    "print('Patches shape: {}'.format(patches.shape))\n",
    "# Here are just two of these patches:\n",
    "print(patches[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
